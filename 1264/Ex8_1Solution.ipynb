{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Exercise 8.1:\n",
    "# Generating Association Rules From Transaction Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "#### In this exercise, you will perform association rule mining with Python. This exercise allows you to analyze the transaction data by identifying frequently co-occurring items in the data set. The goal is to show you how association rules mining with Python can be used to draw relationships between seemingly unrelated items.\n",
    "\n",
    "### Overview\n",
    "\n",
    "You will work on the Online Retail data set. You will:\n",
    "\n",
    "● Use the Apriori algorithm on the data set to mine association rules <br>\n",
    "● Evaluate the derived rules through their measures of support, confidence,\n",
    "and lift\n",
    "\n",
    "1. ❏ Import the **csv** and **pandas** libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ❏ Create a sparse matrix from the external dataset *Groceries.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Groceries.csv', 'r') as f:  \n",
    "    reader = csv.reader(f)\n",
    "    data = list(list(rec) for rec in csv.reader(f)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ❏ Import the **TransactionEncoder** function from **mlxtend.preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ❏ Transform the unique labels in the list into a one-hot encoded array and convert them into a dataframe for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ❏ Import the **apriori** and **association_rules** functions from **mlxtend.frequent_patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ❏ Generate itemsets using the **apriori()** function <br><br>\n",
    "*Hint: Try different values for min_support to see different results. For example, try a min_support of .07 and then try smaller and greater values to see different results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df, min_support=0.07, use_colnames = True)\n",
    "frequent_itemsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ❏ Use a bar chart to visualize the itemset frequencies<br><br>\n",
    "*Hint: You may need to set an appropriate value for min_support in step 6, to avoid getting too cluttered a visualization*<br><br>\n",
    "*Hint2: If the the visualization doesn't appear when you first execute the cell, try re-executing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets.plot.bar(x='itemsets', y='support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ❏ Explore the sizes of the transactions by summing each row (axis=1) and using the **.value_counts()** method to count the number of transactions of each size. The result could then be stored in a dataframe and transposed for easier display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.sum(axis=1).value_counts()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. ❏  Replace **.value_counts()** from the previos step with **.describe()** to generate summary statistics on the transaction sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. ❏ Use the **.sum()** function on the entire dataset to explore the frequency of items across transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. ❏ Divide the summed values in step 10 by the number of rows to explore the proportion of transactions that contain each item<br><br>\n",
    "*Hint: .shape[0] will return the number of rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. ❏ Find association rules in the dataset using the **association_rules()** function and a **confidence** metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. ❏ Sort the rules by **lift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.sort_values(by=['lift'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. ❏ Find rules that have a chocolate antecedent<br><br>\n",
    "*Hint: You may need to modify the min_support value in step 6 to a much lower value (eg. min_support=.01), and re-execute steps 6 and 12, in order to generate any rules in this step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[rules['antecedents'] == {'chocolate'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
